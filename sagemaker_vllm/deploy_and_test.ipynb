{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SageMaker Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Create your container repository\n",
    "\n",
    "open aws console and create a repository for your container: https://us-west-2.console.aws.amazon.com/ecr/create-repository?region=us-west-2\n",
    "\n",
    "for example `236995464743.dkr.ecr.us-west-2.amazonaws.com/sagemaker_endpoint/vllm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "# login\n",
    "!aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin 236995464743.dkr.ecr.us-west-2.amazonaws.com\n",
    "\n",
    "VLLM_VERSION = \"v0.6.0\"\n",
    "REPO_NAME = \"sagemaker_endpoint/vllm\"\n",
    "CONTAINER = f\"236995464743.dkr.ecr.us-west-2.amazonaws.com/{REPO_NAME}:{VLLM_VERSION}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the container\n",
    "\n",
    "demo codes are in `app/`\n",
    "build and push the docker with following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  109.1kB\n",
      "Step 1/9 : ARG VLLM_VERSION\n",
      "Step 2/9 : FROM vllm/vllm-openai:$VLLM_VERSION\n",
      " ---> 714424fc682c\n",
      "Step 3/9 : WORKDIR /app\n",
      " ---> Using cache\n",
      " ---> cdbc00b24d70\n",
      "Step 4/9 : COPY app/ /app\n",
      " ---> Using cache\n",
      " ---> 161d806cbc9c\n",
      "Step 5/9 : RUN export PYTHON_SITEPACKAGES=`python3 -c \"import site; print(site.getsitepackages()[0])\"`; sed -i '/if __name__ == \"__main__\":/i\\@router.get(\"/ping\")\\nasync def ping() -> Response:\\n\\    return await health()\\n\\nfrom typing import Union\\n@router.post(\"/invocations\")\\nasync def invocations(request: Union[ChatCompletionRequest, CompletionRequest],\\n\\                                 raw_request: Request):\\n\\    if isinstance(request, ChatCompletionRequest):\\n\\        return await create_chat_completion(request, raw_request)\\n\\    elif isinstance(request, CompletionRequest):\\n\\        return await create_completion(request, raw_request)\\n\\    else:\\n\\        return JSONResponse(\"unknow request paras\",\\n\\                            status_code=HTTPStatus.BAD_REQUEST)\\n' ${PYTHON_SITEPACKAGES}/vllm/entrypoints/openai/api_server.py; sed -i 's/model: str/model: Optional[str] = None/' ${PYTHON_SITEPACKAGES}/vllm/entrypoints/openai/protocol.py ; sed -i 's/extra=\"forbid\"//1' ${PYTHON_SITEPACKAGES}/vllm/entrypoints/openai/protocol.py ; sed -i '/async def _check_model/,/:$/!b;/:$/a\\        if request.model is None:\\n\\            return None\\n' ${PYTHON_SITEPACKAGES}/vllm/entrypoints/openai/serving_engine.py; sed -i '/def _maybe_get_adapters/,/:$/!b;/:$/a\\        if request.model is None:\\n\\            return None, None\\n' ${PYTHON_SITEPACKAGES}/vllm/entrypoints/openai/serving_engine.py; chmod +x /app/serve\n",
      " ---> Using cache\n",
      " ---> 3d5d6e29f6c2\n",
      "Step 6/9 : EXPOSE 8080\n",
      " ---> Using cache\n",
      " ---> a41a6176f2cd\n",
      "Step 7/9 : ENV PATH=\"/app:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 2289cd2ab454\n",
      "Step 8/9 : ENTRYPOINT []\n",
      " ---> Running in 77c791cb60af\n",
      "Removing intermediate container 77c791cb60af\n",
      " ---> 0ae7f3fd9829\n",
      "Step 9/9 : CMD [\"serve\"]\n",
      " ---> Running in 7e9b6952dd8b\n",
      "Removing intermediate container 7e9b6952dd8b\n",
      " ---> 3ff65f7a99fc\n",
      "Successfully built 3ff65f7a99fc\n",
      "Successfully tagged sagemaker_endpoint/vllm:v0.6.0\n",
      "The push refers to repository [236995464743.dkr.ecr.us-west-2.amazonaws.com/sagemaker_endpoint/vllm]\n",
      "\n",
      "\u001b[1Be97bb603: Preparing \n",
      "\u001b[1B9a7919d7: Preparing \n",
      "\u001b[1B5340c40c: Preparing \n",
      "\u001b[1B4a0ead90: Preparing \n",
      "\u001b[1Bb014ee96: Preparing \n",
      "\u001b[1Bb8c7c911: Preparing \n",
      "\u001b[1Bf132c006: Preparing \n",
      "\u001b[1Ba86d7e24: Preparing \n",
      "\u001b[1Bd2c1da96: Preparing \n",
      "\u001b[1B335e5a99: Preparing \n",
      "\u001b[1B3bb9c80f: Preparing \n",
      "\u001b[1Bffc45974: Preparing \n",
      "\u001b[1Bf7829cb7: Preparing \n",
      "\u001b[1B869b72ab: Preparing \n",
      "\u001b[1B8431b412: Layer already exists \u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[2A\u001b[2Kv0.6.0: digest: sha256:a9bd50d3401a5801dc455b6e89525a10af64ad074bb9520873288a687eb9c107 size: 3466\n"
     ]
    }
   ],
   "source": [
    "!docker build --build-arg VLLM_VERSION={VLLM_VERSION} -t {REPO_NAME}:{VLLM_VERSION} .\n",
    "!docker tag {REPO_NAME}:{VLLM_VERSION} {CONTAINER}\n",
    "!docker push {CONTAINER}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy on SageMaker\n",
    "\n",
    "define the model and deploy on SageMaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1 Init SageMaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.35.9)\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.214.0)\n",
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.44.2)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (1.35.9)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (0.10.2)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (23.2.0)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.26.4)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.25.3)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (24.1)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.5.3)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.3.2)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.0.2)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.21.1)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.2.0)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.0.0)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.0.7)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.32.3)\n",
      "Requirement already satisfied: docker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.1.3)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.66.2)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (5.9.8)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.36.0,>=1.35.9->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.17.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from docker->sagemaker) (1.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (2024.7.4)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.33.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.18.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker) (2024.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.8)\n",
      "Requirement already satisfied: dill>=0.3.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.8)\n",
      "Requirement already satisfied: pox>=0.3.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.16 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.16)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from schema->sagemaker) (21.6.0)\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 sagemaker transformers\n",
    "import re\n",
    "import json\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Prepare model file: deploy vllm by scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the entrypoint of the endpoint is start.sh\n",
      "====================================================\n",
      "#!/bin/bash\n",
      "\n",
      "# port needs to be $SAGEMAKER_BIND_TO_PORT\n",
      "\n",
      "python3 -m vllm.entrypoints.openai.api_server \\\n",
      "    --port $SAGEMAKER_BIND_TO_PORT \\\n",
      "    --trust-remote-code \\\n",
      "    --max-model-len 8192 \\\n",
      "    --model deepseek-ai/deepseek-coder-6.7b-instruct\n",
      "====================================================\n",
      "vllm_by_scripts/\n",
      "vllm_by_scripts/start.sh\n",
      "vllm_by_scripts/.ipynb_checkpoints/\n",
      "vllm_by_scripts/.ipynb_checkpoints/start-checkpoint.sh\n",
      "S3 Code or Model tar ball uploaded to --- > s3://sagemaker-us-west-2-236995464743/sagemaker_endpoint/vllm/deepseek-coder-6-7b-instruct/vllm_by_scripts.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!echo the entrypoint of the endpoint is \"start.sh\"\n",
    "!echo ====================================================\n",
    "!cat vllm_by_scripts/start.sh\n",
    "!echo ====================================================\n",
    "\n",
    "!rm vllm_by_scripts.tar.gz\n",
    "!tar czvf vllm_by_scripts.tar.gz vllm_by_scripts/\n",
    "\n",
    "model_name = \"deepseek-coder-6-7b-instruct\"\n",
    "\n",
    "s3_code_prefix = f\"sagemaker_endpoint/vllm/{model_name}\"\n",
    "bucket = sess.default_bucket() \n",
    "code_artifact = sess.upload_data(\"vllm_by_scripts.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {code_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3 Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endpoint_name: deepseek-coder-6-7b-instruct-2024-09-06-04-25-09-527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: deepseek-coder-6-7b-instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------!"
     ]
    }
   ],
   "source": [
    "model = Model(\n",
    "    name=model_name,\n",
    "    model_data=code_artifact,\n",
    "    image_uri=CONTAINER,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "# 部署模型到endpoint\n",
    "endpoint_name = sagemaker.utils.name_from_base(model_name)\n",
    "print(f\"endpoint_name: {endpoint_name}\")\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.g5.2xlarge',\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test\n",
    "\n",
    "you can invoke your model with SageMaker SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Message api non-stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here is a basic implementation of the Quick Sort algorithm in Python:\n",
      "\n",
      "```python\n",
      "def quick_sort(arr):\n",
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "    else:\n",
      "        pivot = arr[0]\n",
      "        less_than_pivot = [x for x in arr[1:] if x <= pivot]\n",
      "        greater_than_pivot = [x for x in arr[1:] if x > pivot]\n",
      "        return quick_sort(less_than_pivot) + [pivot] + quick_sort(greater_than_pivot)\n",
      "\n",
      "# Test the function\n",
      "arr = [7, 2, 1, 6, 8, 5, 3, 4]\n",
      "print(quick_sort(arr))  # Output: [1, 2, 3, 4, 5, 6, 7, 8]\n",
      "```\n",
      "\n",
      "Quick sort is a divide and conquer algorithm. It works by selecting a 'pivot' element from the array and partitioning the other elements into two sub-arrays, according to whether they are less than or greater than the pivot. The sub-arrays are then recursively sorted.\n",
      "\n",
      "This implementation uses list comprehension to create the less_than_pivot and greater_than_pivot arrays, which can be more efficient than using the append method.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runtime = boto3.client('runtime.sagemaker')\n",
    "\n",
    "payload = {\n",
    "    # \"model\": \"deepseek-ai/deepseek-coder-6.7b-base\",\n",
    "    \"messages\": [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Write a quick sort in python\"\n",
    "    }\n",
    "    ],\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": False\n",
    "}\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "print(json.loads(response['Body'].read())[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2 Message api stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here is a simple implementation of Quick Sort in Python:\n",
      "\n",
      "```python\n",
      "def quick_sort(arr):\n",
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "    else:\n",
      "        pivot = arr[len(arr)//2]\n",
      "        left = [x for x in arr if x < pivot]\n",
      "        middle = [x for x in arr if x == pivot]\n",
      "        right = [x for x in arr if x > pivot]\n",
      "        return quick_sort(left) + middle + quick_sort(right)\n",
      "\n",
      "# Test the function\n",
      "print(quick_sort([3,6,8,10,1,2,1]))\n",
      "```\n",
      "\n",
      "In this code, we first check if the array has one or no elements, in which case it is already sorted. If the array has more than one element, we select a pivot (in this case, the middle element of the array), and create three lists: one for elements less than the pivot, one for elements equal to the pivot, and one for elements greater than the pivot. We then recursively sort the \"less than\" and \"greater than\" lists. The sorted lists are then concatenated with the middle list (which contains all the pivot elements), resulting in a fully sorted array.\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"model\": \"deepseek-ai/deepseek-coder-6.7b-instruct\",\n",
    "    \"messages\": [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Write a quick sort in python\"\n",
    "    }\n",
    "    ],\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = runtime.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "buffer = \"\"\n",
    "for t in response['Body']:\n",
    "    buffer += t[\"PayloadPart\"][\"Bytes\"].decode()\n",
    "    last_idx = 0\n",
    "    for match in re.finditer(r'^data:\\s*(.+?)(\\n\\n)', buffer):\n",
    "        try:\n",
    "            data = json.loads(match.group(1).strip())\n",
    "            last_idx = match.span()[1]\n",
    "            print(data[\"choices\"][0][\"delta\"][\"content\"], end=\"\")\n",
    "        except (json.JSONDecodeError, KeyError, IndexError) as e:\n",
    "            pass\n",
    "    buffer = buffer[last_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Completion api non-stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a simple implementation of the Quick Sort algorithm in Python:\n",
      "\n",
      "```python\n",
      "def quicksort(arr):\n",
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "    \n",
      "    pivot = arr[len(arr) // 2]\n",
      "    left = [x for x in arr if x < pivot]\n",
      "    middle = [x for x in arr if x == pivot]\n",
      "    right = [x for x in arr if x > pivot]\n",
      "    \n",
      "    return quicksort(left) + middle + quicksort(right)\n",
      "\n",
      "# Demonstration\n",
      "arr = [3,6,8,10,1,2,1]\n",
      "print(quicksort(arr))  # Outputs: [1, 1, 2, 3, 6, 8, 10]\n",
      "```\n",
      "\n",
      "This is a divide-and-conquer algorithm. It works by selecting a 'pivot' element from the array and partitioning the other elements into two sub-arrays, according to whether they are less than or greater than the pivot. The avarage time complexity of this algorithm is O(n log n), but in the worst case, it can be O(n^2).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/deepseek-coder-6.7b-instruct\", trust_remote_code=True)\n",
    "messages=[\n",
    "    { 'role': 'user', 'content': \"write a quick sort algorithm in python.\"}\n",
    "]\n",
    "prompt = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
    "\n",
    "payload = {\n",
    "    # \"model\": \"deepseek-ai/deepseek-coder-6.7b-instruct\",\n",
    "    \"prompt\": prompt,\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "print(json.loads(response['Body'].read())[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Completion api stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a simple implementation of the Quick Sort algorithm in Python:\n",
      "\n",
      "```python\n",
      "def quick_sort(arr):\n",
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "    pivot = arr[len(arr) // 2]\n",
      "    left = [x for x in arr if x < pivot]\n",
      "    middle = [x for x in arr if x == pivot]\n",
      "    right = [x for x in arr if x > pivot]\n",
      "    return quick_sort(left) + middle + quick_sort(right)\n",
      "\n",
      "# Example usage:\n",
      "print(quick_sort([3, 6, 8, 10, 1, 2, 1]))\n",
      "# Output: [1, 1, 2, 3, 6, 8, 10]\n",
      "```\n",
      "\n",
      "This implementation uses a divide-and-conquer strategy. The pivot chosen for this implementation is the middle element of the array, but there are many other ways to choose the pivot. The algorithm is then recursively applied to the sub-arrays on the left and right of the pivot. \n",
      "\n",
      "It's important to note that while Quick Sort is typically faster in practice than other O(n log n) algorithms, it is not in-place, meaning it uses extra space proportional to the depth of the recursion, and therefore in the worst-case is slower than other in-place sorting algorithms like Merge Sort.\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"prompt\": prompt,\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = runtime.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "buffer = \"\"\n",
    "for t in response['Body']:\n",
    "    buffer += t[\"PayloadPart\"][\"Bytes\"].decode()\n",
    "    last_idx = 0\n",
    "    for match in re.finditer(r'^data:\\s*(.+?)(\\n\\n)', buffer):\n",
    "        try:\n",
    "            data = json.loads(match.group(1).strip())\n",
    "            last_idx = match.end()\n",
    "            # print(data)\n",
    "            print(data[\"choices\"][0][\"text\"], end=\"\")\n",
    "        except (json.JSONDecodeError, KeyError, IndexError) as e:\n",
    "            pass\n",
    "    buffer = buffer[last_idx:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
