{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SageMaker Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Create your container repository\n",
    "\n",
    "open aws console and create a repository for your container: https://us-west-2.console.aws.amazon.com/ecr/create-repository?region=us-west-2\n",
    "\n",
    "for example `236995464743.dkr.ecr.us-west-2.amazonaws.com/sagemaker_endpoint/vllm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "# login\n",
    "!aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin 236995464743.dkr.ecr.us-west-2.amazonaws.com\n",
    "\n",
    "VLLM_VERSION = \"v0.5.5\"\n",
    "REPO_NAME = \"sagemaker_endpoint/vllm\"\n",
    "CONTAINER = f\"236995464743.dkr.ecr.us-west-2.amazonaws.com/{REPO_NAME}:{VLLM_VERSION}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the container\n",
    "\n",
    "demo codes are in `app/`\n",
    "build and push the docker with following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  76.29kB\n",
      "Step 1/9 : ARG VLLM_VERSION\n",
      "Step 2/9 : FROM vllm/vllm-openai:$VLLM_VERSION\n",
      " ---> d55dc98813f3\n",
      "Step 3/9 : WORKDIR /app\n",
      " ---> Using cache\n",
      " ---> a35af76520a9\n",
      "Step 4/9 : RUN sed -i '/if __name__ == \"__main__\":/i@router.get(\"/ping\")\\nasync def ping() -> Response:\\n    return await health()\\n\\nfrom typing import Union\\n@router.post(\"/invocations\")\\nasync def invocations(request: Union[ChatCompletionRequest, CompletionRequest],\\n                                 raw_request: Request):\\n    if isinstance(request, ChatCompletionRequest):\\n        return await create_chat_completion(request, raw_request)\\n    elif isinstance(request, CompletionRequest):\\n        return await create_completion(request, raw_request)\\n    else:\\n        return JSONResponse(\"unknow request paras\",\\n                            status_code=HTTPStatus.BAD_REQUEST)\\n' /usr/local/lib/python3.10/dist-packages/vllm/entrypoints/openai/api_server.py;\n",
      " ---> Using cache\n",
      " ---> 0f3a4ad83a1a\n",
      "Step 5/9 : COPY app/ /app\n",
      " ---> Using cache\n",
      " ---> 88b42e68ba8e\n",
      "Step 6/9 : EXPOSE 8080\n",
      " ---> Using cache\n",
      " ---> 37789b6dbcb5\n",
      "Step 7/9 : ENV PATH=\"/app:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> bffede4e7142\n",
      "Step 8/9 : ENTRYPOINT []\n",
      " ---> Running in 71ca48b004f0\n",
      "Removing intermediate container 71ca48b004f0\n",
      " ---> 12fc962d272a\n",
      "Step 9/9 : CMD [\"serve\"]\n",
      " ---> Running in 013e2a21eae7\n",
      "Removing intermediate container 013e2a21eae7\n",
      " ---> e98bdcbc3cf8\n",
      "Successfully built e98bdcbc3cf8\n",
      "Successfully tagged sagemaker_endpoint/vllm:v0.5.5\n",
      "The push refers to repository [236995464743.dkr.ecr.us-west-2.amazonaws.com/sagemaker_endpoint/vllm]\n",
      "\n",
      "\u001b[1Bf1dfb526: Preparing \n",
      "\u001b[1Be4b57978: Preparing \n",
      "\u001b[1Bde6fcab9: Preparing \n",
      "\u001b[1Bbe18beaf: Preparing \n",
      "\u001b[1B78e77628: Preparing \n",
      "\u001b[1B8ed8bcb7: Preparing \n",
      "\u001b[1B941cedf6: Preparing \n",
      "\u001b[1B391fa190: Preparing \n",
      "\u001b[1Baf68747f: Preparing \n",
      "\u001b[1Bb36c4600: Preparing \n",
      "\u001b[1B335e5a99: Preparing \n",
      "\u001b[1B3bb9c80f: Preparing \n",
      "\u001b[1Bffc45974: Preparing \n",
      "\u001b[1Bf7829cb7: Preparing \n",
      "\u001b[1B869b72ab: Preparing \n",
      "\u001b[1B8431b412: Layer already exists \u001b[15A\u001b[2K\u001b[7A\u001b[2K\u001b[2A\u001b[2Kv0.5.5: digest: sha256:af5fbe81909ee674377da3a197649df3a1438c66ff1b6a0ae0e6ee5bd9016ccc size: 3678\n"
     ]
    }
   ],
   "source": [
    "!docker build --build-arg VLLM_VERSION={VLLM_VERSION} -t {REPO_NAME}:{VLLM_VERSION} .\n",
    "!docker tag {REPO_NAME}:{VLLM_VERSION} {CONTAINER}\n",
    "!docker push {CONTAINER}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy on SageMaker\n",
    "\n",
    "define the model and deploy on SageMaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1 Init SageMaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.33.2)\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.214.0)\n",
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.44.2)\n",
      "Requirement already satisfied: botocore<1.34.0,>=1.33.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (1.33.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.9.0,>=0.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3) (0.8.2)\n",
      "Collecting attrs<24,>=23.1.0 (from sagemaker)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.35.9-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.26.4)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.25.3)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (24.1)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.5.3)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.3.2)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.0.2)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.21.1)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.2.0)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.0.0)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.0.7)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.32.3)\n",
      "Requirement already satisfied: docker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.1.3)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.66.2)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (5.9.8)\n",
      "Collecting botocore<1.36.0,>=1.35.9 (from boto3)\n",
      "  Downloading botocore-1.35.9-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
      "  Using cached s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.36.0,>=1.35.9->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.17.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from docker->sagemaker) (1.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (2024.7.4)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.33.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.18.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker) (2024.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.8)\n",
      "Requirement already satisfied: dill>=0.3.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.8)\n",
      "Requirement already satisfied: pox>=0.3.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.16 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.16)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Downloading boto3-1.35.9-py3-none-any.whl (139 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Downloading botocore-1.35.9-py3-none-any.whl (12.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m136.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
      "Installing collected packages: attrs, botocore, s3transfer, boto3\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 24.2.0\n",
      "    Uninstalling attrs-24.2.0:\n",
      "      Successfully uninstalled attrs-24.2.0\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.33.2\n",
      "    Uninstalling botocore-1.33.2:\n",
      "      Successfully uninstalled botocore-1.33.2\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.8.2\n",
      "    Uninstalling s3transfer-0.8.2:\n",
      "      Successfully uninstalled s3transfer-0.8.2\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.33.2\n",
      "    Uninstalling boto3-1.33.2:\n",
      "      Successfully uninstalled boto3-1.33.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.32.69 requires botocore==1.34.69, but you have botocore 1.35.9 which is incompatible.\n",
      "langchain-aws 0.1.16 requires boto3<1.35.0,>=1.34.131, but you have boto3 1.35.9 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed attrs-23.2.0 boto3-1.35.9 botocore-1.35.9 s3transfer-0.10.2\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 sagemaker transformers\n",
    "import re\n",
    "import json\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Prepare model file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: deploy vllm by scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the entrypoint of the endpoint is start.sh\n",
      "====================================================\n",
      "#!/bin/bash\n",
      "\n",
      "# port needs to be 8080\n",
      "\n",
      "python3 -m vllm.entrypoints.openai.api_server \\\n",
      "    --port 8080 \\\n",
      "    --trust-remote-code \\\n",
      "    --model deepseek-ai/deepseek-coder-1.3b-instruct\n",
      "====================================================\n",
      "vllm_by_scripts/\n",
      "vllm_by_scripts/start.sh\n",
      "vllm_by_scripts/.ipynb_checkpoints/\n",
      "vllm_by_scripts/.ipynb_checkpoints/start-checkpoint.sh\n",
      "S3 Code or Model tar ball uploaded to --- > s3://sagemaker-us-west-2-236995464743/sagemaker_endpoint/vllm//vllm_by_scripts.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!echo the entrypoint of the endpoint is \"start.sh\"\n",
    "!echo ====================================================\n",
    "!cat vllm_by_scripts/start.sh\n",
    "!echo ====================================================\n",
    "\n",
    "!rm vllm_by_scripts.tar.gz\n",
    "!tar czvf vllm_by_scripts.tar.gz vllm_by_scripts/\n",
    "\n",
    "\n",
    "s3_code_prefix = f\"sagemaker_endpoint/vllm/\"\n",
    "bucket = sess.default_bucket() \n",
    "code_artifact = sess.upload_data(\"vllm_by_scripts.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {code_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: deploy vllm by model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write the model_id to file model_id\n",
      "====================================================\n",
      "deepseek-ai/deepseek-coder-1.3b-instruct\n",
      "====================================================\n",
      "\n",
      "write envs to file .env\n",
      "====================================================\n",
      "# Environment Variables: https://docs.vllm.ai/en/latest/serving/env_vars.html\n",
      "export HF_TOKEN=\"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\"\n",
      "====================================================\n",
      "vllm_by_model_id/\n",
      "vllm_by_model_id/.env\n",
      "vllm_by_model_id/.env.swp\n",
      "vllm_by_model_id/.ipynb_checkpoints/\n",
      "vllm_by_model_id/.ipynb_checkpoints/model_id-checkpoint\n",
      "vllm_by_model_id/model_id\n",
      "S3 Code or Model tar ball uploaded to --- > s3://sagemaker-us-west-2-236995464743/sagemaker_endpoint/vllm//vllm_by_model_id.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!echo write the model_id to file \"model_id\"\n",
    "!echo ====================================================\n",
    "!cat vllm_by_model_id/model_id\n",
    "!echo ====================================================\n",
    "!echo \n",
    "!echo write envs to file \".env\"\n",
    "!echo ====================================================\n",
    "!cat vllm_by_model_id/.env\n",
    "!echo ====================================================\n",
    "\n",
    "!rm vllm_by_model_id.tar.gz\n",
    "!tar czvf vllm_by_model_id.tar.gz vllm_by_model_id/\n",
    "\n",
    "\n",
    "s3_code_prefix = f\"sagemaker_endpoint/vllm/\"\n",
    "bucket = sess.default_bucket() \n",
    "code_artifact = sess.upload_data(\"vllm_by_model_id.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {code_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3 Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endpoint_name: sagemaker-vllm-2024-08-30-09-08-19-576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: sagemaker-vllm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!"
     ]
    }
   ],
   "source": [
    "model = Model(\n",
    "    name=\"sagemaker-vllm\",\n",
    "    model_data=code_artifact,\n",
    "    image_uri=CONTAINER,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "# 部署模型到endpoint\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"sagemaker-vllm\")\n",
    "print(f\"endpoint_name: {endpoint_name}\")\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.g5.2xlarge',\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test\n",
    "\n",
    "you can invoke your model with SageMaker SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Message api non-stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here is a basic implementation of Quick Sort in Python:\n",
      "\n",
      "```python\n",
      "def quick_sort(arr):\n",
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "    pivot = arr[len(arr) // 2]\n",
      "    left = [x for x in arr if x < pivot]\n",
      "    middle = [x for x in arr if x == pivot]\n",
      "    right = [x for x in arr if x > pivot]\n",
      "    return quick_sort(left) + middle + quick_sort(right)\n",
      "```\n",
      "\n",
      "This function works by selecting a 'pivot' element from the array and partitioning the other elements into two sub-arrays, according to whether they are less than or greater than the pivot. The sub-arrays are then recursively sorted.\n",
      "\n",
      "Here's how you can use it:\n",
      "\n",
      "```python\n",
      "print(quick_sort([3,6,8,10,1,2,1]))\n",
      "# Output: [1, 1, 2, 3, 6, 8, 10]\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runtime = boto3.client('runtime.sagemaker')\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"deepseek-ai/deepseek-coder-1.3b-instruct\",\n",
    "    \"messages\": [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Write a quick sort in python\"\n",
    "    }\n",
    "    ],\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": False\n",
    "}\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "print(json.loads(response['Body'].read())[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2 Message api stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here is a simple implementation of a quicksort algorithm in Python:\n",
      "\n",
      "```python\n",
      "def quicksort(arr):\n",
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "    pivot = arr[len(arr) // 2]\n",
      "    left = [x for x in arr if x < pivot]\n",
      "    middle = [x for x in arr if x == pivot]\n",
      "    right = [x for x in arr if x > pivot]\n",
      "    return quicksort(left) + middle + quicksort(right)\n",
      "\n",
      "print(quicksort([3,6,8,10,1,2,1]))\n",
      "```\n",
      "\n",
      "In this code, the quicksort function takes an array as input. If the input array is of length 0 or 1, it is already sorted, so it returns the input array.\n",
      "\n",
      "Otherwise, it chooses a pivot element from the array. It then creates three lists: one for elements less than the pivot, one for elements equal to the pivot, and one for elements greater than the pivot. It then recursively sorts the elements less than and greater than the pivot and concatenates the results and the elements equal to the pivot.\n",
      "\n",
      "The final sorted array is returned by the function. The last two lines of the code call the quicksort function with a sample array and print the result.\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"model\": \"deepseek-ai/deepseek-coder-1.3b-instruct\",\n",
    "    \"messages\": [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Write a quick sort in python\"\n",
    "    }\n",
    "    ],\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = runtime.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "buffer = \"\"\n",
    "for t in response['Body']:\n",
    "    buffer += t[\"PayloadPart\"][\"Bytes\"].decode()\n",
    "    last_idx = 0\n",
    "    for match in re.finditer(r'^data:\\s*(.+?)(\\n\\n)', buffer):\n",
    "        try:\n",
    "            data = json.loads(match.group(1).strip())\n",
    "            last_idx = match.span()[1]\n",
    "            print(data[\"choices\"][0][\"delta\"][\"content\"], end=\"\")\n",
    "        except (json.JSONDecodeError, KeyError, IndexError) as e:\n",
    "            pass\n",
    "    buffer = buffer[last_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Completion api non-stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I can provide a basic quick sort algorithm in Python. Here's a plain version:\n",
      "\n",
      "```python\n",
      "def quickSort(arr):\n",
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "    else:\n",
      "        pivot = arr[0]\n",
      "        less_than_pivot = [x for x in arr[1:] if x <= pivot]\n",
      "        greater_than_pivot = [x for x in arr[1:] if x > pivot]\n",
      "        return quickSort(less_than_pivot) + [pivot] + quickSort(greater_than_pivot)\n",
      "\n",
      "# Example usage:\n",
      "arr = [3,6,8,10,1,2,1]\n",
      "print(quickSort(arr))\n",
      "# Output: [1, 1, 2, 3, 6, 8, 10]\n",
      "```\n",
      "\n",
      "This algorithm works by selecting a 'pivot' element from the array and partitioning the other elements into two sub-arrays, according to whether they are less than or greater than the pivot. The sub-arrays are then recursively sorted.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/deepseek-coder-6.7b-instruct\", trust_remote_code=True)\n",
    "messages=[\n",
    "    { 'role': 'user', 'content': \"write a quick sort algorithm in python.\"}\n",
    "]\n",
    "prompt = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"deepseek-ai/deepseek-coder-1.3b-instruct\",\n",
    "    \"prompt\": prompt,\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "print(json.loads(response['Body'].read())[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Completion api stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here is a simple implementation of the Quick Sort algorithm in Python. The algorithm is a bit modified to handle the last step where you need to compare the pivot with the rightmost element (Hopefully, to make it more compatible with Python's sorting behavior).\n",
      "\n",
      "```python\n",
      "def quick_sort(arr):\n",
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "    else:\n",
      "        pivot = arr[-1]\n",
      "        left = [x for x in arr[:-1] if x < pivot]\n",
      "        middle = [x for x in arr if x == pivot]\n",
      "        right = [x for x in arr[0:-1] if x > pivot]\n",
      "        return quick_sort(left) + middle + quick_sort(right)\n",
      "\n",
      "# Testing the function\n",
      "print(quick_sort([3,6,8,10,1,2,1]))\n",
      "# Output: [1, 1, 2, 3, 6, 8, 10]\n",
      "```\n",
      "\n",
      "This function works by selecting a pivot element from the array and partitioning the other elements into two sub-arrays, according to whether they are less than or greater than the pivot. The sub-arrays are then recursively sorted.\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"model\": \"deepseek-ai/deepseek-coder-1.3b-instruct\",\n",
    "    \"prompt\": prompt,\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = runtime.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "buffer = \"\"\n",
    "for t in response['Body']:\n",
    "    buffer += t[\"PayloadPart\"][\"Bytes\"].decode()\n",
    "    last_idx = 0\n",
    "    for match in re.finditer(r'^data:\\s*(.+?)(\\n\\n)', buffer):\n",
    "        try:\n",
    "            data = json.loads(match.group(1).strip())\n",
    "            last_idx = match.end()\n",
    "            # print(data)\n",
    "            print(data[\"choices\"][0][\"text\"], end=\"\")\n",
    "        except (json.JSONDecodeError, KeyError, IndexError) as e:\n",
    "            pass\n",
    "    buffer = buffer[last_idx:]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
