{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a59cb08-4371-4e83-9f01-5b7a2fd98a62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p ~/.insightface/models/\n",
    "!wget -c https://github.com/facefusion/facefusion-assets/releases/download/models/inswapper_128.onnx -O ~/.insightface/models/inswapper_128.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db956d7-a0a6-4d68-bd31-38682ca79572",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import os.path as osp\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.display import Video\n",
    "\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "\n",
    "sys.path.insert(0,'../src')\n",
    "from display_utils import display_html, html_table, html_text, html_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32410686-ac7b-4f74-b1d6-b082e98e30fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Engine:\n",
    "    def __init__(self):\n",
    "        self.app = FaceAnalysis(name='buffalo_l')\n",
    "        self.app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "        self.swapper = insightface.model_zoo.get_model('inswapper_128.onnx', download=True, download_zip=True)\n",
    "\n",
    "\n",
    "def read_video(video, skip=1):\n",
    "    video_stream = cv2.VideoCapture(video)\n",
    "    while 1:\n",
    "        for _ in range(skip):\n",
    "            still_reading, frame = video_stream.read()\n",
    "        if not still_reading:\n",
    "            video_stream.release()\n",
    "            break\n",
    "        yield frame\n",
    "\n",
    "\n",
    "def bbox_iou(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = abs(max((xB - xA, 0)) * max((yB - yA), 0))\n",
    "    if interArea == 0:\n",
    "        return 0\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = abs((boxA[2] - boxA[0]) * (boxA[3] - boxA[1]))\n",
    "    boxBArea = abs((boxB[2] - boxB[0]) * (boxB[3] - boxB[1]))\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    # return the intersection over union value\n",
    "    return iou\n",
    "\n",
    "\n",
    "class FaceLib:\n",
    "    def __init__(self):\n",
    "        self.faces = {}\n",
    "        self.nums = 0\n",
    "\n",
    "    def simi(self, a, b):\n",
    "        return np.dot(a, np.array(b).T).max()\n",
    "\n",
    "    def norm(self, x):\n",
    "        return x / np.linalg.norm(x)\n",
    "    \n",
    "    def put(self, faces, img):\n",
    "        for face in faces:\n",
    "            for f in self.faces:\n",
    "                # print(self.simi(face[\"embedding\"], self.faces[f][\"embedding\"]))\n",
    "                sim = self.simi(face.normed_embedding, self.faces[f][\"embedding\"])\n",
    "                iou = bbox_iou(face.bbox, self.faces[f][\"prev_bbox\"])\n",
    "                if sim > 0.9:\n",
    "                    self.faces[f][\"prev_bbox\"] = face.bbox\n",
    "                    break\n",
    "                elif sim > 0.8:\n",
    "                    self.faces[f][\"prev_bbox\"] = face.bbox\n",
    "                    self.faces[f][\"embedding\"].append(face.normed_embedding)\n",
    "                    break\n",
    "                elif sim > 0.7 and iou > 0.5:\n",
    "                    self.faces[f][\"prev_bbox\"] = face.bbox\n",
    "                    self.faces[f][\"embedding\"].append(face.normed_embedding)\n",
    "                    break\n",
    "                elif sim > 0.6 and iou > 0.6:\n",
    "                    self.faces[f][\"prev_bbox\"] = face.bbox\n",
    "                    self.faces[f][\"embedding\"].append(face.normed_embedding)\n",
    "                    break\n",
    "                elif sim > 0.5 and iou > 0.7:\n",
    "                    self.faces[f][\"prev_bbox\"] = face.bbox\n",
    "                    self.faces[f][\"embedding\"].append(face.normed_embedding)\n",
    "                    break\n",
    "            else:\n",
    "                x0, y0, x1, y1 = face[\"bbox\"].round().astype(np.int32)\n",
    "                img_h, img_w = img.shape[:2]\n",
    "                h = (y1 - y0) // 2\n",
    "                w = (x1 - x0) // 2\n",
    "                x0, y0, x1, y1 = max(x0 - w, 0), max(y0 - h, 0), min(x1 + w, img_w), min(y1 + h, img_h)\n",
    "                self.faces[self.nums] = {\n",
    "                    \"img\": Image.fromarray(cv2.cvtColor(img[y0:y1,x0:x1], cv2.COLOR_BGR2RGB)),\n",
    "                    \"embedding\": [face.normed_embedding],\n",
    "                    \"prev_bbox\": face.bbox,\n",
    "                }\n",
    "                self.nums += 1\n",
    "        \n",
    "    def most_simi(self, face):\n",
    "        sim_index = -1\n",
    "        sim_value = -1\n",
    "        for f in self.faces:\n",
    "            sim = self.simi(face.normed_embedding, self.faces[f][\"embedding\"])\n",
    "            if sim > sim_value:\n",
    "                sim_value = sim\n",
    "                sim_index = f\n",
    "        return sim_index, sim_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2a780a-f943-4f6c-a489-aad76866ba71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "engine = Engine()\n",
    "facelib0 = FaceLib()\n",
    "\n",
    "display(Video(\"test_video.mp4\"))\n",
    "\n",
    "for idx, img in enumerate(tqdm(read_video(\"test_video.mp4\"))):\n",
    "    faces = engine.app.get(img)\n",
    "    facelib0.put(faces, img)\n",
    "print(\"total faces\", len(facelib0.faces))\n",
    "display_html(\n",
    "    html_table([\n",
    "        list(facelib0.faces.keys()),\n",
    "        [html_image(v[\"img\"]) for v in facelib0.faces.values()],\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3831f-940c-4d32-8fd4-7834513f9390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "swap_map = {\n",
    "    0: \"faces/xinzhilei.webp\",\n",
    "    4: \"faces/xinzhilei.webp\",\n",
    "    11: \"faces/xinzhilei.webp\",\n",
    "    \n",
    "    1: \"faces/tangyan.webp\",\n",
    "    10: \"faces/tangyan.webp\",\n",
    "    \n",
    "    3: \"faces/huge.webp\",\n",
    "    \n",
    "    7: \"faces/musk.jpeg\",\n",
    "\n",
    "    8: \"faces/ronaldo.jpg\",\n",
    "    \n",
    "}\n",
    "\n",
    "for k in swap_map:\n",
    "    img = cv2.imread(swap_map[k])\n",
    "    face = engine.app.get(img)[0]\n",
    "    x0, y0, x1, y1 = face[\"bbox\"].round().astype(np.int32)\n",
    "    img_h, img_w = img.shape[:2]\n",
    "    h = (y1 - y0) // 2\n",
    "    w = (x1 - x0) // 2\n",
    "    x0, y0, x1, y1 = max(x0 - w, 0), max(y0 - h, 0), min(x1 + w, img_w), min(y1 + h, img_h)\n",
    "    swap_map[k] = {\n",
    "        \"img\": Image.fromarray(cv2.cvtColor(img[y0:y1,x0:x1], cv2.COLOR_BGR2RGB)),\n",
    "        \"face\": face,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "display_html(\n",
    "    html_table([\n",
    "        [\"\"] + list(swap_map.keys()),\n",
    "        [\"source\"] + [html_image(facelib0.faces[k][\"img\"]) for k in swap_map],\n",
    "        [\"target\"] +[html_image(v[\"img\"]) for v in swap_map.values()],\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2f32f9-72d2-4f93-929d-98b1e8d667e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "!rm temp.mp4\n",
    "\n",
    "video_writer = None\n",
    "\n",
    "for idx, img in enumerate(tqdm(read_video(\"test_video.mp4\"))):\n",
    "    faces = engine.app.get(img)\n",
    "    if video_writer is None:\n",
    "        video_writer = cv2.VideoWriter(\"temp.mp4\", fourcc, 23.98, img.shape[1::-1])\n",
    "    for face in faces:\n",
    "        sim_index, sim_value = facelib0.most_simi(face)\n",
    "        if sim_value > 0.6 and sim_index in swap_map:\n",
    "            img = engine.swapper.get(img, face, swap_map[sim_index][\"face\"], paste_back=True)\n",
    "    video_writer.write(img)\n",
    "\n",
    "video_writer.release()\n",
    "\n",
    "!ffmpeg -i temp.mp4 -i test_video.mp4 -vcodec h264 -y out.mp4\n",
    "display(Video(\"out.mp4\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_insightface",
   "language": "python",
   "name": "conda_insightface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
